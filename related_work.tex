\section{Related Work}\label{sec:related_work}

The problem of ``vocabulary quality'' is closely related to the more general problem of “data quality”, which has intensively been discussed in data and information systems research. \cite{Pipino2002,Batini2009} argue that dealing with data quality should involve both “subjective perceptions of the individuals” and “objective measurements based on the data set in question”. We see our work as a contribution to the latter and believe that the results of SKOS quality measures must be combined with domain knowledge, and therefore human expertise, to make final quality judgements.

A vast number of publications in the field of designing, validating and testing controlled vocabularies is available. Many of them propose properties \cite{Soergel1995}, design guidelines \cite{Svenonius2003,...} or metrics \cite{Elkin2002,Kless2010} aiming to improve, e.g., retrieval precision and recall, consistency and multilinguality. The work is based on various sources like, e.g., review of existing vocabularies~\cite{Soergel1995} or survey-based studies~\cite{Pinto2008}. However, there are hardly any formally defined quality indicators that can be automatically assessed without further knowledge about the application domain, targeted user group or usage scenario.

%For controlled vocabularies, \cite{Svenonius2003} argues precision and recall to be “the chief objectives of any retrieval language” and proposes a set of design guidelines (e.g., term selection, structural and syntactical considerations) aiming to improve these objectives. Elkin and XXX? [Elkin2002#] identify general quality metrics and structural and maintainability considerations for controlled vocabularies in the health domain, which cover issues like non-redundancy, consistency, and multilinguality of concepts? Soergel [Soergel1995#] mentions properties of “good” thesauri like, e.g., support for synonym and hierarchic expansion or request-oriented indexing. As negative properties of the AAT Soergel points out, e.g., missing cross-references, incomplete facet analysis, the monohierarchical layout and shortcomings in term form and choice. On the positive side he mentions, e.g., presence of scope notes, definition of related terms and some definitions of synonyms. Pinto [Pinto2008#] performs a survey-based study comparing perceived and expected properties (“variables”) of thesauri used in social science databases. The findings exposed need for “considerable improvement” in the structural perspective (e.g., equivalence and associative relationships), but also regarding “performance” variables (e.g., explanatory notes or expected performance) and “format” issues (e.g., ergonomics and display). Some of the identified variables (e.g, pre-coordination, searching options) are hard do assess automatically or are application dependent, others aren’t exactly defined or formalized. However, neither of them suggest any automatic assessment methods, which can be applied to controlled Web vocabularies.

Research on the notion of “data quality” has also been conducted in Semantic Web research. For general datasets, \cite{Heath2011,Hogan2010} propose best practices and ..   \cite{Tartir2007} 

Hogan and ??? [Hogan2009#] identify four categories of common errors and shortcomings in RDF documents. Some of them are also of great importance and can be adopted for assessing the quality of SKOS vocabularies, especially considering interoperability issues like e.g., dereferencability and use of undefined classes and properties. However, the author’s focus lies on RDF datasets in general, thus features of controlled vocabularies are not covered. This is also the case for [Tartir2007#] who propose a framework for evaluation and ranking of Ontologies. Given the fact that vocabularies usually extend the SKOS schema only to a very limited degree by defining subclasses and subproperties, the metrics defined in [Tartir2007] are not considered applicable to these vocabularies.

[Arpinar2006#] define three types of conflicts that may occur in ontologies. Based on these types, the ontology maintainers can create rules in RuleML or SWRL to find violations in their ontologies. Although not using a rule language, we express quality criteria formally, following a very similar approach.

[Gangemi2005#] introduce three “measure types for ontology evaluation” (dimensions), i.e. structural, functional and usability-related measures. The structural exploits the graph structure of an ontology and defines a number of measure like, e.g., absolute, average or maximum depth and breadth, number of leaf nodes, number of siblings or density. While for many of the measures, its applicability for controlled vocabularies is not immediately clear, some (e.g., cycle ratio, inverse relations) resemble common patterns in controlled vocabularies and thus are represented in our catalog of quality criteria. Functional dimensions are measures related to how well an ontology fits its intended purpose like, e.g., recall, precision and accuracy. They are highly context-dependent, however, we expect most of our identified criteria to impact these dimensons. In the usability dimension, Gangemi et al. mention three analytical levels for usability profiling: recognition, efficiency, and interfacing. Since they don’t go into details on what the implications for thesauri are, we try to complement this in the rationale of our identified quality crtieria. [Brank2005#] provide a concise overview on ontology evaluation approaches
Linked Data Quality

[Yeganeh2011#] propose a method to convert semi-structured data (e.g., XML files) into “high-quality Linked Data”. Their notion of quality encompasses usage of HTTP URIs, URI dereferencability, linkage of related objects as well as merging and detection of duplicate resources.
